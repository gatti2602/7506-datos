{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lt5420\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Root de archivos de datos\n",
    "root_dir = '../data/'\n",
    "\n",
    "#Lee menos data si es testing\n",
    "is_testing = False\n",
    "\n",
    "# Cantidad minima de aparicion de equipos en un dataframe\n",
    "min_devices = 5\n",
    "\n",
    "# Identificador unico de equipos\n",
    "device_uuid = ['ref_hash']\n",
    "\n",
    "# Ventanas de tiempo\n",
    "windows = pd.DataFrame({\n",
    "    'begin_date': [dt.datetime(2019,4,18),dt.datetime(2019,4,21),dt.datetime(2019,4,24)],\n",
    "    'window_nr':[1,2,3]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado de Features\n",
    "\n",
    "Se utilizan 3 ventanas de tiempo y se procesan los dataframes para obtener features de esas 3 ventanas por separado. \n",
    "\n",
    "Como resultado se obtiene un dataset de features mas grande cuyos datos no se solapan en tiempo. Por lo que son validos para la prediccion. \n",
    "\n",
    "Se realiza la lectura y limpiado de los dataframes principales, con los mismos se realiza el filtrado y armado de los features. \n",
    "\n",
    "---\n",
    "## 1. Lectura de DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Testing, #records: 47409528\n"
     ]
    }
   ],
   "source": [
    "#Optimizado para menos memoria\n",
    "auction_dtypes = {\n",
    "    'device_id': np.int64,\n",
    "    'source_id': np.int8\n",
    "}\n",
    "\n",
    "auctions = pd.read_csv(root_dir + 'auctions.csv.gzip',\n",
    "                       compression = 'gzip',\n",
    "                       dtype = auction_dtypes,\n",
    "                       usecols=list(auction_dtypes.keys()) + ['date'],\n",
    "                       parse_dates = ['date'])\n",
    "auctions.rename({'device_id':'ref_hash',\n",
    "                 'date':'created'}, inplace=True, axis='columns')\n",
    "auctions['n'] = 1\n",
    "\n",
    "# Para hacer pruebas ocupando menos memoria se hace un sampleo aleatorio de la mitad del dataframe y se elimina el resto\n",
    "if is_testing:\n",
    "    auctions = auctions.sample(frac=.30)\n",
    "    print(\"Is Testing, #records:\", auctions['n'].sum())\n",
    "else:\n",
    "    print(\"Not Testing, #records:\", auctions['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs_dtypes = {\n",
    "    'application_id': np.int32,\n",
    "    'ref_hash': np.int64, \n",
    "    #'click_hash':'category',\n",
    "    'attributed': 'category',\n",
    "    'implicit': 'category',\n",
    "    #'device_countrycode': 'object', \n",
    "    'device_brand': 'object',\n",
    "    'device_model': 'object', \n",
    "    'session_user_agent': 'object', \n",
    "    'user_agent': 'object', \n",
    "    'event_uuid':'object',\n",
    "    'kind': 'object',\n",
    "    'wifi': 'object', \n",
    "    'trans_id': 'object', \n",
    "    #'ip_address':'object', \n",
    "    'device_language': 'object'\n",
    "}\n",
    "install_cols = list(installs_dtypes.keys()) + ['created']\n",
    "installs = pd.read_csv(root_dir + 'installs.csv.gzip', \n",
    "                       compression='gzip', \n",
    "                       usecols=install_cols,\n",
    "                       dtype= installs_dtypes,\n",
    "                      parse_dates=['created'])\n",
    "\n",
    "installs['n'] = 1\n",
    "print('#records:', installs['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_dtypes = {\n",
    "    'advertiser_id': np.int64, \n",
    "    'action_id': np.float, \n",
    "    'source_id': np.int8, \n",
    "    'latitude' : np.float64, \n",
    "    'longitude': np.float64, \n",
    "    'wifi_connection': np.bool, \n",
    "    'carrier_id': 'object', \n",
    "    'trans_id': 'object',\n",
    "    'os_minor':'object', \n",
    "    'agent_device' : 'object', \n",
    "    'os_major': 'object', \n",
    "    'specs_brand': 'category', \n",
    "    'brand': 'object',\n",
    "    'timeToClick': np.float64, \n",
    "    'touchX': 'object', \n",
    "    'touchY': 'object', \n",
    "    'ref_hash':np.int64,\n",
    "    'created' : 'object'\n",
    "}\n",
    "clicks = pd.read_csv(root_dir + 'clicks.csv.gzip', \n",
    "                     compression='gzip',\n",
    "                     usecols=list(clicks_dtypes.keys()) + ['created'],\n",
    "                     dtype=clicks_dtypes,\n",
    "                     parse_dates=['created'])\n",
    "clicks['n'] = 1\n",
    "print('#records:', clicks['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dtypes = {\n",
    "    'event_id': np.int64,\n",
    "    'ref_hash': np.int64,\n",
    "    'application_id': np.int64,\n",
    "    'attributed': np.bool,\n",
    "    'device_os_version': 'object',\n",
    "    'device_brand': 'object',\n",
    "    'device_model': 'object',\n",
    "    'device_city': 'object',\n",
    "    'session_user_agent': 'object',\n",
    "    'trans_id': 'category',\n",
    "    'user_agent': 'object',\n",
    "    'event_uuid': 'object',\n",
    "    'carrier': 'object',\n",
    "    'kind': 'object',\n",
    "    'device_os': 'object',\n",
    "    'wifi': np.bool,\n",
    "    'connection_type': 'object',\n",
    "    #'ip_address': np.int64,\n",
    "    #'device_language': 'category'\n",
    "}\n",
    "events_cols = list(events_dtypes.keys()) + ['date']\n",
    "events = pd.read_csv(root_dir + 'events.csv.gzip', \n",
    "                     compression='gzip',\n",
    "                     dtype=events_dtypes,\n",
    "                     usecols=events_cols,\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "events.rename({'date':'created'}, inplace=True, axis='columns')\n",
    "events['n'] = 1\n",
    "# Para hacer pruebas ocupando menos memoria se hace un sampleo aleatorio de la mitad del dataframe y se elimina el resto\n",
    "if is_testing:\n",
    "    events = events.sample(frac=.30)\n",
    "    print(\"Is Testing, #records:\", events['n'].sum())\n",
    "else:\n",
    "    print(\"Not Testing, #records:\", events['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels a submitir con las predicciones\n",
    "to_predict = pd.read_csv(root_dir + 'target_competencia_ids.csv')\n",
    "to_predict = to_predict.apply(lambda x: np.int64(x['ref_hash'][0:x['ref_hash'].find('_')]), axis='columns').drop_duplicates().to_frame()\n",
    "to_predict.columns = ['ref_hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_hashes = pd.read_csv(root_dir+'unique_hashes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Arreglo de los datos\n",
    "\n",
    "### Separo las semanas de entrenamiento\n",
    "\n",
    "Se utiliza el siguiente metodo: \n",
    "\n",
    "1. Ventana del 18 al 20 inclusive (1) -> Predice valores entre el 21 y 24 (2)\n",
    "2. Ventana del 21 al 23 inclusive (2) -> Predice valores entre el 24 y 26 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego la ventana de tiempo\n",
    "auctions = auctions.loc[auctions['ref_hash'].isin(unique_hashes['ref_hash'])]\n",
    "auctions.sort_values(by='created',inplace=True)\n",
    "auctions = pd.merge_asof(auctions,windows,left_on='created',right_on='begin_date').drop('begin_date', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs = installs.loc[installs['ref_hash'].isin(unique_hashes['ref_hash'])]\n",
    "installs.sort_values(by='created',inplace=True)\n",
    "installs = pd.merge_asof(installs,windows,left_on='created',right_on='begin_date').drop('begin_date', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = clicks.loc[clicks['ref_hash'].isin(unique_hashes['ref_hash'])]\n",
    "clicks.sort_values(by='created',inplace=True)\n",
    "clicks = pd.merge_asof(clicks,windows,left_on='created',right_on='begin_date').drop('begin_date', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events.loc[events['ref_hash'].isin(unique_hashes['ref_hash'])]\n",
    "events.sort_values(by='created',inplace=True)\n",
    "events = pd.merge_asof(events,windows,left_on='created',right_on='begin_date').drop('begin_date', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Arreglo de Auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminados: 736875\n"
     ]
    }
   ],
   "source": [
    "#Elimino los registros con menos de un minimo de entradas, ya que no hay mucho que predecir en estos casos\n",
    "group = ['ref_hash','window_nr']\n",
    "orig_count = auctions['n'].sum()\n",
    "auctions = auctions.groupby(group, sort = False).filter(lambda x: x['n'].sum() >= min_devices) \n",
    "last_count = auctions['n'].sum()\n",
    "print('Eliminados:', orig_count-last_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions.sort_values(by=group+['created'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions['next_date'] = auctions.groupby(group, as_index = False, sort=False)['created'].transform(lambda x: x.shift(-1))\n",
    "auctions = auctions.loc[(~auctions['next_date'].isnull())]\n",
    "auctions['secs_to_next'] = (auctions['next_date'] - auctions['created']).transform(lambda x: round(x.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>ref_hash</th>\n",
       "      <th>source_id</th>\n",
       "      <th>n</th>\n",
       "      <th>window_nr</th>\n",
       "      <th>next_date</th>\n",
       "      <th>secs_to_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9146132</th>\n",
       "      <td>2019-04-19 19:40:28.465866</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 02:52:26.892880</td>\n",
       "      <td>25918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162626</th>\n",
       "      <td>2019-04-20 02:52:26.892880</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 02:59:02.509230</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194917</th>\n",
       "      <td>2019-04-20 02:59:02.509230</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 03:06:01.675788</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229465</th>\n",
       "      <td>2019-04-20 03:06:01.675788</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 03:08:57.388160</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244486</th>\n",
       "      <td>2019-04-20 03:08:57.388160</td>\n",
       "      <td>41863526108385</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-20 03:11:26.463903</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            created        ref_hash  source_id  n  window_nr  \\\n",
       "9146132  2019-04-19 19:40:28.465866  41863526108385          8  1          1   \n",
       "11162626 2019-04-20 02:52:26.892880  41863526108385          3  1          1   \n",
       "11194917 2019-04-20 02:59:02.509230  41863526108385          3  1          1   \n",
       "11229465 2019-04-20 03:06:01.675788  41863526108385          3  1          1   \n",
       "11244486 2019-04-20 03:08:57.388160  41863526108385          3  1          1   \n",
       "\n",
       "                          next_date  secs_to_next  \n",
       "9146132  2019-04-20 02:52:26.892880         25918  \n",
       "11162626 2019-04-20 02:59:02.509230           396  \n",
       "11194917 2019-04-20 03:06:01.675788           419  \n",
       "11229465 2019-04-20 03:08:57.388160           176  \n",
       "11244486 2019-04-20 03:11:26.463903           149  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auctions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Arreglo de datos de Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['kind'] = installs['kind'].str.replace(' ','_')\n",
    "installs['kind'] = installs['kind'].str.replace('af_app_open ','af_app_opened')\n",
    "installs['kind'] = installs['kind'].str.replace('af_app_opend','af_app_opened')\n",
    "installs['kind'] = installs['kind'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['device_brand','device_model','session_user_agent','user_agent','kind','wifi','device_language']:\n",
    "    installs[i] = installs[i].fillna('unknown')\n",
    "installs['device_brand'] = installs['device_brand'].astype('category')\n",
    "installs['device_model'] = installs['device_model'].astype('category')\n",
    "installs['session_user_agent'] = installs['session_user_agent'].astype('category')\n",
    "installs['user_agent'] = installs['user_agent'].astype('category')\n",
    "installs['kind'] = installs['kind'].astype('category')\n",
    "installs['wifi'] = installs['wifi'].astype('category')\n",
    "installs['device_language'] = installs['device_language'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Arreglo de datos de Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.touchX = clicks.touchX.apply(lambda x: np.float64(x))\n",
    "clicks.touchY = clicks.touchY.apply(lambda x: np.float64(x))\n",
    "clicks['created'] = clicks['created'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['carrier_id','os_minor', 'agent_device', 'brand', 'os_major']:\n",
    "    clicks[i] = clicks[i].fillna('unknown').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Arreglo de datos de Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['device_os_version','device_brand','device_model','device_city','session_user_agent','user_agent','carrier','kind','device_os','connection_type']:\n",
    "    events[i] = events[i].fillna('unknown').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Armado de Features\n",
    "\n",
    "A continuacion se comienzan a extraer los distintos features que formaran el set de entrenamiento. \n",
    "Se cruza cada ventana con los labels que se desean predecir. \n",
    "\n",
    "Para entrenar el set debe decidirse como utilizar los datos de las distintas ventanas. \n",
    "\n",
    "Se tomaran los datos en 2 ventanas diferentes y se validaran con dos ventanas diferentes, de esta forma no deberia haber problemas de solapamiento y se maximiza la cantidad de datos.\n",
    "\n",
    "Para el set final puede armarse un set de labels con los valores de los ultimos 3 dias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiempo promedio de arribos\n",
    "\n",
    "Se desea saber el tiempo promedio entre arribos de los dispositivos a las encuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = auctions.loc[auctions['secs_to_next'] < 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = unique_hashes\n",
    "temp['window_nr'] = 1\n",
    "devices = temp.copy()\n",
    "temp['window_nr'] = 2\n",
    "devices = devices.append(temp)\n",
    "temp['window_nr'] = 3\n",
    "devices = devices.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    662110\n",
       "2    662110\n",
       "1    662110\n",
       "Name: window_nr, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices['window_nr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices.set_index(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiempo desde ultima aparicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = auctions.sample(frac=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimo los segundos hasta la siguiente ventana y luego me quedo con el minimo tiempo\n",
    "max_dates = pd.DataFrame({'w_max_date': [dt.datetime(2019,4,21),dt.datetime(2019,4,24),dt.datetime(2019,4,27)], 'window_nr' : [1,2,3]})\n",
    "time = sample.merge(max_dates, on='window_nr', how='left')\\\n",
    "               .set_index(group)\\\n",
    "               .transform(lambda x: round((x['w_max_date'] - x['created']).total_seconds()), axis = 1)\\\n",
    "               .rename('secs_since_last_arrival')\\\n",
    "               .reset_index()\\\n",
    "               .groupby(group,)['secs_since_last_arrival']\\\n",
    "               .agg('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = devices.merge(time, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de apariciones en encuestas en la ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_auctions = auctions.groupby(group ,sort=False)['n'].count().rename('auctions_total')\n",
    "devices = devices.merge(auctions,how = 'left', left_index=True, right_index=True)\n",
    "devices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de apariciones en encuestas en la ultima hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = auctions.merge(max_dates, on='window_nr', how='left').set_index(group)\n",
    "time = time.loc[time['created'] > (time['w_max_date']-timedelta(hours=1))]\\\n",
    "           .groupby(group,as_index=False,sort=false)['n']\\\n",
    "           .sum()\n",
    "           .rename('auctions_last_hour')\n",
    "            \n",
    "devices = devices.merge(time, how='left', left_index=True, right_index=True)\n",
    "devices.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
