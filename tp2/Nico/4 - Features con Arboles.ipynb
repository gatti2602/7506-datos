{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import datetime as dt\n",
    "import gc\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Root de archivos de datos\n",
    "root_dir = '../data/'\n",
    "\n",
    "#Lee menos data si es testing\n",
    "is_testing = True\n",
    "\n",
    "# Cantidad minima de aparicion de equipos en un dataframe\n",
    "min_devices = 10\n",
    "\n",
    "# Identificador unico de equipos\n",
    "device_uuid = ['ref_hash']\n",
    "\n",
    "# Ventanas de tiempo\n",
    "windows = pd.DataFrame({\n",
    "'window_nr':[1,2,3,4],\n",
    "'n': 1,\n",
    "'min_date': dt.datetime(2019,4,18),\n",
    "'max_date': [dt.datetime(2019,4,21),dt.datetime(2019,4,22),dt.datetime(2019,4,23),dt.datetime(2019,4,24)]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediccion de Tiempos de Arribo\n",
    "===============================\n",
    "\n",
    "Se utilizan los distintos dataframes para armar un set de features que sirvan para predecir el tiempo hasta la aparicion de un dispositivo nuevamente. \n",
    "\n",
    "Este notebook tiene la siguiente estructura: \n",
    "\n",
    "1. Lectura de los Dataframes\n",
    "2. Arreglo de los datos\n",
    "3. Armado de Features\n",
    "4. Armado de labels\n",
    "5. Armado del set de pruebas\n",
    "6. Training del Modelo Predictivo\n",
    "7. Predicciones\n",
    "8. Evaluacion \n",
    "\n",
    "------------------------------\n",
    "## 1. Lectura de los Dataframes\n",
    "\n",
    "Se realiza la carga de los dataframes en memoria para el armado del modelo predictivo. La lectura se hace optimizando los tipos de datos a fin de utilizar la menor cantidad de memoria posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Testing, #records: 47409528\n"
     ]
    }
   ],
   "source": [
    "#Optimizado para menos memoria\n",
    "auction_dtypes = {\n",
    "    'ref_type_id': np.int8,\n",
    "    'device_id': np.int64,\n",
    "    'source_id': np.int8\n",
    "}\n",
    "\n",
    "auctions = pd.read_csv(root_dir + 'auctions.csv.gzip',\n",
    "                       compression = 'gzip',\n",
    "                       dtype = auction_dtypes,\n",
    "                       parse_dates = ['date'])\n",
    "auctions.rename({'device_id':'ref_hash',\n",
    "                 'ref_type_id':'ref_type'}, inplace=True, axis='columns')\n",
    "auctions['n'] = 1\n",
    "\n",
    "# Para hacer pruebas ocupando menos memoria se hace un sampleo aleatorio de la mitad del dataframe y se elimina el resto\n",
    "if is_testing:\n",
    "    auctions = auctions.sample(frac=.30)\n",
    "    print(\"Is Testing, #records:\", auctions['n'].sum())\n",
    "else:\n",
    "    print(\"Not Testing, #records:\", auctions['n'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#records: 481511\n"
     ]
    }
   ],
   "source": [
    "installs_dtypes = {\n",
    "    'application_id': np.int32,\n",
    "    'ref_type': np.int64,\n",
    "    'ref_hash': np.int64, \n",
    "    #'click_hash':'category',\n",
    "    'attributed': 'category',\n",
    "    'implicit': 'category',\n",
    "    #'device_countrycode': 'object', \n",
    "    'device_brand': 'object',\n",
    "    'device_model': 'object', \n",
    "    'session_user_agent': 'object', \n",
    "    'user_agent': 'object', \n",
    "    'event_uuid':'object',\n",
    "    'kind': 'object',\n",
    "    'wifi': 'object', \n",
    "    'trans_id': 'object', \n",
    "    #'ip_address':'object', \n",
    "    'device_language': 'object'\n",
    "}\n",
    "install_cols = list(installs_dtypes.keys()) + ['created']\n",
    "installs = pd.read_csv(root_dir + 'installs.csv.gzip', \n",
    "                       compression='gzip', \n",
    "                       usecols=install_cols,\n",
    "                       dtype= installs_dtypes,\n",
    "                      parse_dates=['created'])\n",
    "\n",
    "installs['n'] = 1\n",
    "print('#records:', installs['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.loc[installs['ref_type'] == 1891515180541284343, 'ref_type'] = 1\n",
    "installs.loc[installs['ref_type'] == 1494519392962156891, 'ref_type'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#records: 64296\n"
     ]
    }
   ],
   "source": [
    "clicks_dtypes = {\n",
    "    'advertiser_id': np.int8, \n",
    "    'action_id': np.int32, \n",
    "    'source_id': np.int8, \n",
    "    'latitude' : np.float64, \n",
    "    'longitude': np.float64, \n",
    "    'wifi_connection': np.bool, \n",
    "    'carrier_id': np.int16, \n",
    "    'trans_id': 'object',\n",
    "    'os_minor':'object', \n",
    "    #'agent_device' : 'category', \n",
    "    #'os_major': 'category', \n",
    "    'specs_brand': 'category', \n",
    "    #'brand': np.int8,\n",
    "    'timeToClick': np.float64, \n",
    "    #'touchX': np.float64, \n",
    "    #'touchY': np.float64, \n",
    "    'ref_type':np.int64, \n",
    "    'ref_hash':np.int64,\n",
    "    'created' : 'object'\n",
    "}\n",
    "clicks = pd.read_csv(root_dir + 'clicks.csv.gzip', \n",
    "                     compression='gzip',\n",
    "                     low_memory=False,\n",
    "                     parse_dates=['created'])\n",
    "clicks['n'] = 1\n",
    "print('#records:', clicks['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Testing, #records: 7744581\n"
     ]
    }
   ],
   "source": [
    "events_dtypes = {\n",
    "    'event_id': np.int64,\n",
    "    'ref_type': np.int64,\n",
    "    'ref_hash': np.int64,\n",
    "    'application_id': np.int64,\n",
    "    'attributed': np.bool,\n",
    "    'device_os_version': 'object',\n",
    "    'device_brand': 'object',\n",
    "    'device_model': 'object',\n",
    "    'device_city': 'object',\n",
    "    'session_user_agent': 'object',\n",
    "    'trans_id': 'category',\n",
    "    'user_agent': 'object',\n",
    "    'event_uuid': 'object',\n",
    "    'carrier': 'object',\n",
    "    'kind': 'object',\n",
    "    'device_os': 'object',\n",
    "    'wifi': np.bool,\n",
    "    'connection_type': 'object',\n",
    "    #'ip_address': np.int64,\n",
    "    #'device_language': 'category'\n",
    "}\n",
    "events_cols = list(events_dtypes.keys()) + ['date']\n",
    "events = pd.read_csv(root_dir + 'events.csv.gzip', \n",
    "                     compression='gzip',\n",
    "                     dtype=events_dtypes,\n",
    "                     usecols=events_cols,\n",
    "                     parse_dates=['date'])\n",
    "events['n'] = 1\n",
    "# Para hacer pruebas ocupando menos memoria se hace un sampleo aleatorio de la mitad del dataframe y se elimina el resto\n",
    "if is_testing:\n",
    "    events = events.sample(frac=.30)\n",
    "    print(\"Is Testing, #records:\", events['n'].sum())\n",
    "else:\n",
    "    print(\"Not Testing, #records:\", events['n'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels a submitir con las predicciones\n",
    "\n",
    "to_predict = pd.read_csv(root_dir + 'target_final_competencia_revamped.csv')\n",
    "to_predict = to_predict.apply(lambda x: np.int64(x['ref_hash'][0:x['ref_hash'].find('_')]), axis='columns').drop_duplicates().to_frame()\n",
    "to_predict.columns = ['ref_hash']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Arreglo de los Datos\n",
    "\n",
    "### 2.1 Arreglo de datos de Auctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminados: 699013\n"
     ]
    }
   ],
   "source": [
    "#Elimino los registros con menos de un minimo de entradas, ya que no hay mucho que predecir en estos casos\n",
    "orig_count = auctions['n'].sum()\n",
    "auctions = auctions.groupby(device_uuid, sort = False).filter(lambda x: x['n'].sum() >= min_devices) \n",
    "last_count = auctions['n'].sum()\n",
    "print('Eliminados:', orig_count-last_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions.sort_values(by=(device_uuid+['date']), inplace=True)\n",
    "auctions['next_date'] = auctions.groupby(device_uuid, as_index = False, sort=False)['date'].transform(lambda x: x.shift(-1))\n",
    "auctions = auctions.loc[(~auctions['next_date'].isnull())]\n",
    "auctions['secs_to_next'] = (auctions['next_date'] - auctions['date']).transform(lambda x: round(x.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Arreglo de datos de Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['kind'] = installs['kind'].str.replace(' ','_')\n",
    "installs['kind'] = installs['kind'].str.replace('af_app_open ','af_app_opened')\n",
    "installs['kind'] = installs['kind'].str.replace('af_app_opend','af_app_opened')\n",
    "installs['kind'] = installs['kind'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['device_brand','device_model','session_user_agent','user_agent','kind','wifi','device_language']:\n",
    "    installs[i] = installs[i].fillna('unknown')\n",
    "installs['device_brand'] = installs['device_brand'].astype('category')\n",
    "installs['device_model'] = installs['device_model'].astype('category')\n",
    "installs['session_user_agent'] = installs['session_user_agent'].astype('category')\n",
    "installs['user_agent'] = installs['user_agent'].astype('category')\n",
    "installs['kind'] = installs['kind'].astype('category')\n",
    "installs['wifi'] = installs['wifi'].astype('category')\n",
    "installs['device_language'] = installs['device_language'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Arreglo de datos de Clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.touchX = clicks.touchX.apply(lambda x: np.float64(x))\n",
    "clicks.touchY = clicks.touchY.apply(lambda x: np.float64(x))\n",
    "clicks['created'] = clicks['created'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['carrier_id','os_minor', 'agent_device', 'brand', 'os_major']:\n",
    "    clicks[i] = clicks[i].fillna('unknown').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Arreglo de datos de Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['device_os_version','device_brand','device_model','device_city','session_user_agent','user_agent','carrier','kind','device_os','connection_type']:\n",
    "    events[i] = events[i].fillna('unknown').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Separado de las ventanas de tiempo\n",
    "----------------------------------\n",
    "\n",
    "### Separo las semanas de entrenamiento\n",
    "\n",
    "Se pueden utilizar distintos metodos: \n",
    "\n",
    "- Se arman ventanas de 3 días para predecir 3 dias\n",
    "- Se arman ventanas de n-1 dias para predecir n a n+2 dias.\n",
    "\n",
    "Para el caso de estudio se utiliza la opcion de maximizar la cantidad de datos para predecir cada ventana.\n",
    "\n",
    "Los datos pueden entonces estar en las siguientes ventanas y deben solo usarse para predecir la ventana correspondiente en los sets de training.\n",
    "\n",
    "Las ventanas de los sets de entrenamiento son: \n",
    "\n",
    "1. 21 al 23\n",
    "2. 22 al 24\n",
    "3. 23 al 25\n",
    "4. 24 al 26\n",
    "\n",
    "Entonces las ventanas armadas serán:\n",
    "1. 18 al 20\n",
    "2. 18 al 21\n",
    "3. 18 al 22\n",
    "4. 18 al 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Armado de Features\n",
    "\n",
    "A continuacion se comienzan a extraer los distintos features que formaran el set de entrenamiento. \n",
    "Se cruza cada ventana con los labels que se desean predecir. \n",
    "\n",
    "Para entrenar el set debe decidirse como utilizar los datos de las distintas ventanas. \n",
    "\n",
    "- Una opcion será mezclar todos los datos pero hay que decidir que hacer con los equipos que aparecen mas de una vez. \n",
    "\n",
    "- La segunda opcion es entrenar 4 modelos distintos y verificar que haya una mejora en todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entreno con ventana de 18 al 23 y valido con ventana del 24 al 26\n",
    "cutoff_date = windows.set_index('window_nr').loc[4,'max_date']\n",
    "\n",
    "train_auctions = auctions.loc[auctions['date'] < cutoff_date]\n",
    "train_installs = installs.loc[installs['created'] < cutoff_date]\n",
    "train_events = events.loc[events['date'] < cutoff_date]\n",
    "train_clicks = clicks.loc[clicks['created'] < cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_installs = installs.loc[installs['created'] >= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = train_auctions[device_uuid].drop_duplicates()\n",
    "devices['ref_hash'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de tiempo entre arribos\n",
    "\n",
    "Se desea saber el tiempo promedio entre arribos de los dispositivos a las encuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered = auctions.loc[auctions['secs_to_next'] < 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_auctions.groupby(device_uuid, as_index='False')['secs_to_next'].mean().to_frame()\n",
    "temp.columns = ['secs_to_next_mean']\n",
    "\n",
    "devices = devices.merge(temp, how='left', on=device_uuid).set_index(device_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiempo desde ultima aparicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = train_auctions['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = train_auctions.groupby(device_uuid).apply(lambda x: round((max_date - x['date'].max()).total_seconds())).to_frame()\n",
    "time.columns = ['secs_since_last_arrival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = devices.merge(time, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de apariciones en encuestas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_auctions = train_auctions.groupby(device_uuid)['n'].count().to_frame()\n",
    "amount_auctions.columns = ['auctions_total']\n",
    "devices = devices.merge(amount_auctions,how = 'left', left_index=True, right_index=True)\n",
    "devices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_last_auctions = train_auctions.groupby(device_uuid).apply(lambda x: x.loc[x['date'] > (max_date - timedelta(hours=1)),'n'].count()).to_frame()\n",
    "amount_last_auctions.columns = ['auctions_last_hour']\n",
    "devices = devices.merge(amount_last_auctions, how='left', left_index=True, right_index=True)\n",
    "devices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secuencia de ultimos 5 eventos del dispositivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Armado de Labels \n",
    "\n",
    "### 4.1. Prediccion de Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ref_hash = devices.reset_index()[device_uuid].drop_duplicates()\n",
    "len(all_ref_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs['ref_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3\n",
    "j=1\n",
    "installs_training = pd.DataFrame()\n",
    "\n",
    "for i in range(21,25): #[19, 20, 21, 22, 23, 24]\n",
    "    print(\"Ventana: \", j)\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    temp[device_uuid + ['date_install']] = installs.loc[(installs['created'].dt.day >= i) & (installs['created'].dt.day < (i+window))]\\\n",
    "                                                    .groupby(device_uuid, as_index=False)['created'].min()\n",
    "    temp['window_nr'] = j\n",
    "    temp['window_date_start'] = dt.datetime(2019,4,i)\n",
    "    temp['secs_to_install'] = (temp['date_install']-temp['window_date_start']).transform(lambda x: x.total_seconds())\n",
    "    print(\"  Encontrados: \", len(temp))\n",
    "    installs_training = installs_training.append(temp,sort=True)\n",
    "    \n",
    "    #Agrego los que no se encontraron en esta ventana pero si estan en installs (aparecen en alguna)\n",
    "    temp = all_ref_hash.merge(installs_training.loc[installs_training['window_nr'] == j], how='left',on=device_uuid)\n",
    "    temp = temp.loc[temp['window_nr'].isnull()]\n",
    "    temp['window_nr'] = j\n",
    "    temp['window_date_start'] = dt.datetime(2019,4,i)\n",
    "    temp['date_install'] = dt.datetime(2019,4,i+window)\n",
    "    temp['secs_to_install'] = (temp['date_install']-temp['window_date_start']).transform(lambda x: x.total_seconds())\n",
    "    print(\"  Agregados sin installs en esta ventana: \", len(temp))\n",
    "    installs_training = installs_training.append(temp,sort=True)\n",
    "    \n",
    "    #Agrego los que no se encontraron en install pero se deben predecir conversiones\n",
    "    #temp = to_predict.merge(installs_training.loc[installs_training['window_nr'] == j], how='left', on='ref_hash')\n",
    "    #temp = temp.loc[temp['window_nr'].isnull()]\n",
    "    #print(\"  Agregados sin installs pero en lista a predecir: \", len(temp))\n",
    "    #temp['window_nr'] = j\n",
    "    #temp['window_date_start'] = dt.datetime(2019,4,i)\n",
    "    #temp['date_install'] = dt.datetime(2019,4,i+window)\n",
    "    #temp['secs_to_install'] = (temp['date_install']-temp['window_date_start']).transform(lambda x: x.total_seconds())\n",
    "    #installs_training = installs_training.append(temp,sort=True)\n",
    "    \n",
    "    j = j+1\n",
    "\n",
    "sorted_installs = installs_training.sort_values(device_uuid + ['window_nr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_installs['window_nr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = devices.merge(sorted_installs.loc[sorted_installs['window_nr'] == 4, device_uuid+['secs_to_install']].set_index(device_uuid), left_index=True,right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=devices\n",
    "y=training_set['secs_to_install']\n",
    "\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "regr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
